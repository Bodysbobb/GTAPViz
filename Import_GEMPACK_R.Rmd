---
title: "Import GTAP Results from .SL4 and .HAR to CSV/STATA/R/TXT Using R"
author: "Pattawee Puangchit"
date: "02/06/2025"
bibliography: references.bib  
output:
  pdf_document:
    toc: true
    number_sections: true
    latex_engine: lualatex
header-includes:
  - \usepackage{xcolor}
  - \usepackage{hyperref}
  - \usepackage[hang,flushmargin]{footmisc}
  - \hypersetup{colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue}
  - \setlength{\footnotemargin}{0em}
  - \setlength{\footnotesep}{0.5em}
urlcolor: blue
linkcolor: blue
---

# Introduction {#sec:introduction}

This R code is based on the HARr package, which enables processing `.sl4` and `.har` result files from the GTAPv7 model @gtapv7mod in R, using the package developed by @ivanic2023gempack.\footnote{This package is already included in the `<Package>` chunk installed via `devtools::github`. For details about the package, see: \href{https://github.com/Bodysbobb/HARplus}{HARplus}.}

## R Packages
```{r Package, echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
rm(list=ls())
packages <- c("tidyverse", "writexl", "dplyr", "devtools", 
              "openxlsx", "readxl", "knitr", "rmarkdown", "data.table", 
              "ggplot2", "tcltk", "gridExtra", "haven", "citation", "tinytex", "bookdown")

install.packages(setdiff(packages, rownames(installed.packages())))  
lapply(packages, library, character.only = TRUE)

if (!require("HARplus")) {
    devtools::install_github('https://github.com/Bodysbobb/HARplus')
}
library("HARplus")
```

## Project Setting {#sec:project-setting}

To use this R code, all solution files, including `.sl4` and `.har`, must be saved from RUNGTAP or CMD and placed in the same folder.

### Directory {#sec:directory}
Adjust the `<project.folder>` directory to your desired path. If you maintain the same folder structure as in this code, you may not need to modify the input (`<input.folder>`), output (`<output.folder>`), or mapping (`<map.folder>`) directories.

By default, this R code assumes that `<project.folder>` contains the following three main folders:

-   **in** – Stores all input files (i.e., `.sl4` and `.har`). See the [Solution files](#sec:input-files) for details.
-   **out** – Stores all exported output files.
-   **map** – Stores the mapping `.xlsx` file (**critical for processing**).

![Example of Project Folder](pic/projectfolder.png)

## Mapping Files {#sec:mapping-files}

The **`<OutputMapping.xlsx>`** specifies the variables to extract from the solution files `<SL4File sheet>` and the HAR file `<HARFile sheet>`. All required variables must be listed in the `"Ori.Var.Name"` column.

For `"Description"` and `"Unit"`, you may:

- Leave the columns blank and put `"No"` in `<info.mode>` [setting](#sec:setting) to exclude these columns.  
  \footnote{If you leave them blank and put `"Yes"` instead of `"No"`, the result will return an empty column in your output.}

- Manually define **all variables** and put `"Yes"` in `<info.mode>` [setting](#sec:setting).

- Leave the columns blank and put `"GTAP"` in `<info.mode>` [setting](#sec:setting) to get the default definition and unit based on GTAPv7.  
  \footnote{The GTAP default can only define variables based on the GTAPv7 default set. If you add additional variables to the model, you must manually define the `"Description"` and `"Unit"` in the sheet if needed.}

- Define only some variables, leave others blank, and put `"Mix"` in `<info.mode>` [setting](#sec:setting) to get the definition based on your input for defined variables and the GTAP default for the others.


| Ori.Var.Name | New.Var.Name | Description         | Unit        |
|--------------|--------------|---------------------|-------------|
| qgdp         | realgdp      | Real GDP Index (%)  | percent     |
| EV           | Welfare      | Welfare Equivalents | million USD |
| pebfactreal  | costendw     | Cost of endownment  | percent     |

: Example of SL4File sheet


## Input Files {#sec:input-files}

The `<case.name>` variable in [setting](#sec:setting) contains experiment names from which results will be extracted and merged into a single output for further analysis, such as graph creation. Multiple experiments can be included, but increasing their number will extend processing time.

### Input Files Format

All input files must be stored in `<input.folder>` (default: `"in"` inside `<project.folder>`). File names must follow `<case.name>` to ensure consistency between input each `.sl4` file must have a corresponding `-WEL.HAR` file

-   `EXP1.sl4`, `EXP1-WEL.har`
-   `EXP2.sl4`, `EXP2-WEL.har`

![Example of Input Folder](pic/input.folder.png)


## Output Files {#sec:output-files}

This R code, by default, can generate four output formats: CSV, STATA, R, and Text files, defined by `<csv.output>`, `<stata.output>`, `<r.output>`, and `<txt.output>`, respectively. In [setting](#sec:setting), placing `"Yes"` or `"No"` for the required format. 

At the end, the code will automatically generate a `"README.xlsx"` file, reporting the location of exported key variables (i.e., sheet names). Since GTAP results contain different data dimensions, the output will be separated by dimension (1D, 2D, 3D).

For 1D and 2D data, results are automatically grouped into `"Region"` and `"Sector"`—distinguishing variables reported at the sector level from those reported by region—for easier data manipulation.

However, data larger than 3D will be reported separately by dimension, with output files named according to their original dimension names. An exception is `qxs`, which represents bilateral trade changes; if selected for export, it will be placed in the `"BilateralTrade"` sheet.


# Flexibility and Applicability {#sec:flexibility}

This R code is designed to extract any variable from `.SL4` and `.HAR` files, even those newly created by users that are not included in the original GTAP model. 

Furthermore, this code is adaptable to any version of the GTAP CGE model, provided that the `.SL4` and `.HAR` files exist and adhere to the required format.\footnote{With minor modifications, this R script can also be used to extract all types of three-dimensional data formatted in `.SL4` and `.HAR`.} 

In cases where `HARFile.HAR` files are unavailable, the script will still function, but the decomposition component will be skipped.


# Seting {#sec:setting}
```{r}
# Directory
project.folder <- "D:/GitHub/GTAP-Results-using-R/TestData"

# Sub Directories (Optional)
input.folder <- paste0(project.folder,"/in")
output.folder <- paste0(project.folder,"/out")
map.folder <- paste0(project.folder,"/map")

# Define experiment name / output name 
case.name <- c("EXP1", "EXP2")

# Adding Description / Unit (Yes/No/GTAP/Mix)
## Yes - Your input from the mapping sheet
info.mode <- "GTAP"

# Output: (CSV, STATA, R) 
# "Yes" to opt for this output format, "No" to skip the output format
csv.output <- "YES"    
stata.output <- "Yes"  
r.output <- "Yes"
txt.output <- "Yes"   

#-----DEV PERIOD ONLY--------#
script_dir <- "D:/GitHub/GTAPViz/R"
script_files <- list.files(script_dir, pattern = "\\.R$", full.names = TRUE)
lapply(script_files, source)
```

# Preparing Input Data

The rest of the code prepares the input, creates functions, and exports the output. You may skip to the [Execution](#sec:execution) section for details on executing functions separately.

```{r}
# ==============================================================================
# DO NOT EDIT BELOW THIS LINE
# ==============================================================================
# Load Input Data from Excel Mapping File
mapping.output <- paste0(map.folder, "/OutputMapping.xlsx")
sl4map <- read_xlsx(mapping.output, sheet = "SL4File")
harmap <- read_xlsx(mapping.output, sheet = "HARFile")
default.info <- read_xlsx(mapping.output, sheet = "Default")

# Define the format of output
output_formats <- c(
  "csv"    = tolower(csv.output) == "yes",
  "stata"  = tolower(stata.output) == "yes",
  "rds"    = tolower(r.output) == "yes",
  "txt"    = tolower(txt.output) == "yes"
)

output_formats <- names(output_formats)[output_formats]

# -----------------------------------------------------
# Checking input files and displaying warnings
# -----------------------------------------------------
dir_path <- input.folder
# Get list of all files in the directory
files <- list.files(dir_path, full.names = FALSE, ignore.case = TRUE)

# Get specific file lists
sl4_list <- files[grepl("\\.sl4$", files, ignore.case = TRUE)]
wel_list <- files[grepl("-wel\\.har$", files, ignore.case = TRUE)]

# Extract base names (removing extensions), trimming spaces, and normalizing case
sl4_bases <- tolower(trimws(sub("\\.sl4$", "", sl4_list, ignore.case = TRUE)))
wel_bases <- tolower(trimws(sub("-wel\\.har$", "", wel_list, ignore.case = TRUE)))

# Match each SL4 file with a corresponding WEL file
matched_pairs <- intersect(sl4_bases, wel_bases)
unmatched_sl4 <- setdiff(sl4_bases, wel_bases)
unmatched_wel <- setdiff(wel_bases, sl4_bases)

# Count files and matches
total_sl4_files <- length(sl4_list)  # Total .sl4 files
total_wel_files <- length(wel_list)  # Total -WEL.har files
total_matched_files <- length(matched_pairs)  # Total matched pairs
total_unmatched_sl4 <- length(unmatched_sl4)  # Unmatched .sl4 files
total_unmatched_wel <- length(unmatched_wel)  # Unmatched -WEL.har files

# Check for unmatched files
if (total_unmatched_sl4 > 0 || total_unmatched_wel > 0) {
  stop(sprintf(
    "⚠️ There are unmatched files:\nUnmatched SL4 Files: %d\nUnmatched WEL Files: %d\nEnsure all file names follow the naming convention (e.g., ABC.sl4 and ABC-WEL.har).",
    total_unmatched_sl4, total_unmatched_wel
  ))
}

# Check for missing case files
case_names_lower <- tolower(trimws(case.name))
missing_cases <- setdiff(case_names_lower, matched_pairs)
if (length(missing_cases) > 0) {
  stop("⚠️ Please verify that all experiments defined in `case.name` have solution files (`.sl4`) and decomposition files (`-WEL.har`).")
}

# Base success message
report <- sprintf(
  "All files are correctly matched. There are %d total solution files and %d total decomposition files.\nProcessing experiments: %s",
  total_sl4_files, total_wel_files,
  paste(case.name, collapse = ", ")
)

# Print final report
cat(report)

```


# Function {#sec:functionsdefinitions}

```{r}

if (length(sl4map$Ori.Var.Name) > 0) {
  # Extract the list of variables to load from sl4map
  variables_to_load <- sl4map$Ori.Var.Name
  
  # Check for QXS in sl4map
  has_qxs <- any(grepl("qxs", sl4map$Ori.Var.Name, ignore.case = TRUE))
  
  # Load only selected variables
  sl4.data.raw <- setNames(
    lapply(case.name, function(scenario) {
      load_sl4x(
        file.path(input.folder, paste0(scenario, ".sl4")),
        select_header = variables_to_load
      )
    }),
    case.name
  )
  
  # Mapping Files
  priority_list <- list(
    "Sector" = c("COMM", "ACTS"),
    "Region" = c("REG")
  )
  
  # Extract by Dimension
  grouped_sl4 <- do.call(
    group_data_by_dims,  
    c(
      list(
        experiment_names = names(sl4.data.raw),
        auto_rename = TRUE,
        priority = priority_list,
        subtotal_level = TRUE
      ),
      sl4.data.raw  
    )
  )
  
  # If QXS exists, separate bilateral trade data before adding mapping info
  if (has_qxs) {
    # Find bilateral trade dimension
    bilateral_dim <- grep("COMM.*REG.*REG", names(grouped_sl4), value = TRUE)
    
    if (length(bilateral_dim) > 0) {
      # Extract bilateral trade data
      bilateral_trade <- grouped_sl4[[bilateral_dim]]
      
      # Add mapping info to bilateral trade data
      bilateral_trade <- add_mapping_info(bilateral_trade, sl4map)
      
      # Remove bilateral dimension from grouped_sl4
      grouped_sl4[[bilateral_dim]] <- NULL
      
      # Create bilateral trade file
      export_data(
        data = bilateral_trade,
        output_path = file.path(output.folder, "BilateralTrade"),
        format = output_formats,
        create_subfolder = TRUE,
        multi_sheet_xlsx = TRUE,
        report_output = TRUE
      )
    }
  }
  
  # Add Description, New Variable Name, and Unit to remaining data
  grouped_sl4 <- add_mapping_info(grouped_sl4, sl4map)
  
  # Macro Data
  if (any(tolower(sl4map$Ori.Var.Name) %in% "macros", na.rm = TRUE)) {
    Macros <- do.call(gtap_macros_data, list(sl4.data.raw))
    Macros <- add_unit_col(Macros, "GTAPunit")
    
    # Export Macros
    export_data(
      data = Macros,
      output_path = file.path(output.folder, "Macros"),
      format = output_formats,
      create_subfolder = TRUE,
      multi_sheet_xlsx = TRUE,
      report_output = TRUE
    )
  }
  
  # Export remaining SL4 data
  export_data(
    data = grouped_sl4,
    output_path = file.path(output.folder),
    format = output_formats,
    create_subfolder = TRUE,
    multi_sheet_xlsx = TRUE,
    report_output = TRUE
  )
}


if (length(harmap$Ori.Var.Name) > 0) {
  
  # Extract the list of variables to load from harmap
  variables_to_load <- harmap$Ori.Var.Name
  
  # Load only selected variables
  har.data.raw <- setNames(
    lapply(case.name, function(scenario) {
      load_harx(
        file.path(input.folder, paste0(scenario, "-WEL.har")),
        select_header = variables_to_load
      )
    }),
    case.name
  )
  
  # Extract by Dimension
  har_data <- do.call(
    get_data_by_var,  
    c(
      list(
        experiment_names = names(har.data.raw),
        subtotal_level = TRUE,
        merge_data = TRUE
      ),
      har.data.raw  
    )
  )
  
  # Add Description, New Variable Name, and Unit
  har_data <- add_mapping_info(har_data, harmap)
  
  # Export  HAR
  export_data(
    data = har_data, 
    output_path = file.path(output.folder), 
    format = "xlsx",
    create_subfolder = TRUE,
    multi_sheet_xlsx = TRUE,
    xlsx_filename = "Decomposition",
    report_output = TRUE
  )
}


```

# Export {#sec:export}

```{r}
#---------------------------------------------------------------------------#
# Create mapping for output sheet locations
#---------------------------------------------------------------------------#

#---------------------------------------------------------------------------#
# Exporting Function
#---------------------------------------------------------------------------#
# Validate output format settings first
is_yes <- function(value) {
  tolower(trimws(value)) == "yes"
}

is_no <- function(value) {
  tolower(trimws(value)) == "no"
}

# Function to validate input is either yes or no (case insensitive)
is_valid_input <- function(value) {
  clean_value <- tolower(trimws(value))
  clean_value %in% c("yes", "no")
}

# Check for invalid values (anything that's not a variation of yes/no)
invalid_values <- character()

if (!is_valid_input(csv.output)) invalid_values <- c(invalid_values, "csv.output")
if (!is_valid_input(stata.output)) invalid_values <- c(invalid_values, "stata.output")
if (!is_valid_input(r.output)) invalid_values <- c(invalid_values, "r.output")
if (!is_valid_input(txt.output)) invalid_values <- c(invalid_values, "txt.output")

if (length(invalid_values) > 0) {
  stop(sprintf("
Please specify either 'yes' or 'no' (case insensitive) under 'Directory' section for: %s", 
               paste(invalid_values, collapse = ", ")))
}

# Function to safely check if object exists
safe_exists <- function(x) {
  exists(deparse(substitute(x)))
}

# Function to create directory if it doesn't exist
create_dir_if_missing <- function(dir_path) {
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
}

# Only create directories for enabled output types
if (is_yes(csv.output)) {
  csv_output_dir <- file.path(output.folder, "CSV")
  create_dir_if_missing(csv_output_dir)
}
if (is_yes(stata.output)) {
  stata_output_dir <- file.path(output.folder, "STATA")
  create_dir_if_missing(stata_output_dir)
}
if (is_yes(r.output)) {
  r_output_dir <- file.path(output.folder, "R")
  create_dir_if_missing(r_output_dir)
}
if (is_yes(txt.output)) {
  txt_output_dir <- file.path(output.folder, "TXT")
  create_dir_if_missing(txt_output_dir)
}

# Function to process CommRegReg data with qxs separation
process_comm_reg_reg <- function(data) {
  if ("Variable" %in% names(data)) {
    bilateral_trade <- data[data$Variable == "qxs", ]
    other_data <- data[data$Variable != "qxs", ]
    
    return(list(
      main = if(nrow(other_data) > 0) other_data else NULL,
      bilateral = if(nrow(bilateral_trade) > 0) bilateral_trade else NULL
    ))
  }
  return(list(main = data, bilateral = NULL))
}



# Function to safely export data based on enabled output types
safe_export_data <- function(data, base_filename) {
  # CSV export
  if (is_yes(csv.output)) {
    tryCatch({
      write.csv(data, 
                file.path(csv_output_dir, paste0(base_filename, ".csv")), 
                row.names = FALSE)
      message(sprintf("Successfully exported %s to CSV", base_filename))
    }, error = function(e) {
      message(sprintf("Error exporting %s to CSV: %s", base_filename, e$message))
    })
  }
  
  # STATA export
  if (is_yes(stata.output)) {
    tryCatch({
      write_dta(as.data.frame(data), 
                file.path(stata_output_dir, paste0(base_filename, ".dta")))
      message(sprintf("Successfully exported %s to STATA", base_filename))
    }, error = function(e) {
      message(sprintf("Error exporting %s to STATA: %s", base_filename, e$message))
    })
  }
  
  # R export
  if (is_yes(r.output)) {
    tryCatch({
      data_to_save <- data
      save(data_to_save, 
           file = file.path(r_output_dir, paste0(base_filename, ".RData")))
      message(sprintf("Successfully exported %s to RData", base_filename))
    }, error = function(e) {
      message(sprintf("Error exporting %s to RData: %s", base_filename, e$message))
    })
  }
  
  # TXT export
  if (is_yes(txt.output)) {
    tryCatch({
      # Convert to basic data.frame first
      data_df <- as.data.frame(data, stringsAsFactors = FALSE)
      
      # Write using write.table with proper formatting
      write.table(data_df, 
                  file = file.path(txt_output_dir, paste0(base_filename, ".txt")),
                  sep = "\t",  # Tab separated
                  row.names = FALSE, 
                  quote = FALSE,
                  na = "")
      
      message(sprintf("Successfully exported %s to TXT", base_filename))
    }, error = function(e) {
      message(sprintf("Error exporting %s to TXT: %s", base_filename, e$message))
    })
  }
}

# Function to safely process dimensional lists with special handling
safe_process_dim_list <- function(list_name, prefix) {
  tryCatch({
    if (exists(list_name, envir = .GlobalEnv)) {
      dim_list <- get(list_name, envir = .GlobalEnv)
      if (is.list(dim_list) && length(dim_list) > 0) {
        for (name in names(dim_list)) {
          base_filename <- paste0(prefix, "_", name)
          data <- dim_list[[name]]
          
          # Special handling for CommRegReg
          if (name == "CommRegReg") {
            processed_data <- process_comm_reg_reg(data)
            
            # Export main CommRegReg data if it exists
            if (!is.null(processed_data$main)) {
              safe_export_data(processed_data$main, base_filename)
            }
            
            # Export bilateral trade data if it exists
            if (!is.null(processed_data$bilateral)) {
              bilateral_filename <- paste0(prefix, "_BilateralTrade")
              safe_export_data(processed_data$bilateral, bilateral_filename)
            }
          } else {
            # Normal export for other cases
            safe_export_data(data, base_filename)
          }
          
          message(sprintf("Completed processing %s - %s", list_name, name))
        }
      }
    }
  }, error = function(e) {
    message(sprintf("Note: Error processing %s: %s", list_name, e$message))
  })
}

# Function to export decomposition sheets if they exist
safe_export_decomposition <- function() {
  # Handle EV decomposition
  if(length(ev.var) > 0 && exists("All_EVDecomp.sheet")) {
    safe_export_data(All_EVDecomp.sheet, "EVDecomp")
  }
  
  # Handle ToT decomposition
  if(length(tot.var) > 0 && exists("All_ToTDecomp.sheet")) {
    safe_export_data(All_ToTDecomp.sheet, "ToTDecomp")
  }
}

# Check if any output type is enabled before proceeding
if (!any(sapply(c(csv.output, stata.output, r.output, txt.output), is_yes))) {
  stop("No output types are enabled. Set at least one output type to 'yes' to 
       export data.")
} else {
  # Process dimensional lists
  dim_lists <- list(
    "one.dimens.list" = "1D",
    "two.dimens.list" = "2D",
    "three.dimens.list" = "3D"
  )
  
  # First create and copy README report to all enabled folders
  copy_readme_report()
  
  # Then process all dimensional lists
  for (list_name in names(dim_lists)) {
    safe_process_dim_list(list_name, dim_lists[[list_name]])
  }
  
  # Export decomposition sheets if they exist
  safe_export_decomposition()
  
  # Print summary of enabled output types
  message("\n=== Export Summary ===")
  
  if (is_yes(csv.output)) {
    message("✓ CSV files saved successfully in: ", csv_output_dir)
  }
  if (is_yes(stata.output)) {
    message("✓ STATA files saved successfully in: ", stata_output_dir)
  }
  if (is_yes(r.output)) {
    message("✓ R files saved successfully in: ", r_output_dir)
  }
  if (is_yes(txt.output)) {  
    message("✓ TXT files saved successfully in: ", txt_output_dir)
  }

  message("==================")
}
```

# References {.unnumbered}
