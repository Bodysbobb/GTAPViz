validation_results$status <- "warning"
validation_results$messages <- c(validation_results$messages,
sprintf("⚠️ harmap is missing columns: %s",
paste(missing_cols, collapse = ", ")),
"These are required for info.mode = 'Yes' or 'Mix'")
# Ask for confirmation
cat(paste(validation_results$messages, collapse = "\n"), "\n")
use_gtapv7 <- .ask_confirmation(
"Do you want to proceed using GTAPv7 definitions for missing values? (Y/N): ")
if (!use_gtapv7) {
validation_results$proceed <- FALSE
return(validation_results)
}
validation_results$messages <- character()  # Clear messages after confirmation
}
}
}
# Add messages for NULL mappings
if (process_sl4 && is.null(sl4map)) {
validation_results$messages <- c(validation_results$messages,
"ℹ️ sl4map is NULL - all SL4 variables will be extracted with GTAPv7 mapping")
}
if (process_har && is.null(harmap)) {
validation_results$messages <- c(validation_results$messages,
"ℹ️ harmap is NULL - all HAR variables will be extracted with GTAPv7 mapping")
}
# Add messages for skipped processes
if (!process_sl4) {
validation_results$messages <- c(validation_results$messages,
"ℹ️ sl4map is FALSE - SL4 processing will be skipped")
}
if (!process_har) {
validation_results$messages <- c(validation_results$messages,
"ℹ️ harmap is FALSE - HAR processing will be skipped")
}
# Case Names Validation
if (length(case.name) == 0) {
validation_results$status <- "error"
validation_results$messages <- c(validation_results$messages,
"❌ No experiment names provided",
"ℹ️ Please define experiment variable with experiment names")
validation_results$proceed <- FALSE
return(validation_results)
}
# Check for duplicate case names
if (length(case.name) != length(unique(case.name))) {
duplicate_cases <- case.name[duplicated(case.name)]
validation_results$status <- "error"
validation_results$messages <- c(validation_results$messages,
"❌ Duplicate experiment names found:",
paste("   -", duplicate_cases),
"ℹ️ Each experiment name must be unique")
validation_results$proceed <- FALSE
return(validation_results)
}
# Input Files Validation
files <- list.files(input.folder, full.names = FALSE, ignore.case = TRUE)
# Get specific file lists
sl4_files <- files[grepl("\\.sl4$", files, ignore.case = TRUE)]
har_files <- files[grepl("-wel\\.har$", files, ignore.case = TRUE)]
# Extract base names, trimming spaces, and normalizing case
sl4_bases <- tolower(trimws(sub("\\.sl4$", "", sl4_files, ignore.case = TRUE)))
har_bases <- tolower(trimws(sub("-wel\\.har$", "", har_files, ignore.case = TRUE)))
case_names_lower <- tolower(trimws(case.name))
# Check if required files exist
if (process_sl4 && length(sl4_files) == 0) {
validation_results$status <- "error"
validation_results$messages <- c(validation_results$messages,
"❌ No .sl4 files found in the input folder but sl4map is specified")
validation_results$proceed <- FALSE
return(validation_results)
}
if (process_har && length(har_files) == 0) {
validation_results$status <- "error"
validation_results$messages <- c(validation_results$messages,
"❌ No -WEL.har files found in the input folder but harmap is specified")
validation_results$proceed <- FALSE
return(validation_results)
}
# Check for complete absence of case files
available_bases <- c()
if (process_sl4) available_bases <- c(available_bases, sl4_bases)
if (process_har) available_bases <- c(available_bases, har_bases)
missing_cases <- setdiff(case_names_lower, available_bases)
if (length(missing_cases) == length(case_names_lower)) {
validation_results$status <- "error"
validation_results$messages <- c(validation_results$messages,
sprintf("❌ None of the specified experiments were found: %s",
paste(case.name[!case_names_lower %in% available_bases],
collapse = ", ")))
validation_results$proceed <- FALSE
return(validation_results)
}
# Check for partial case matches
partial_cases <- intersect(case_names_lower, available_bases)
if (length(partial_cases) < length(case_names_lower) &&
length(partial_cases) > 0) {
missing_cases <- case.name[!case_names_lower %in% available_bases]
validation_results$status <- "warning"
validation_results$messages <- c(validation_results$messages,
sprintf("⚠️ Some specified experiments were not found: %s",
paste(missing_cases, collapse = ", ")))
# Ask for confirmation
cat(paste(validation_results$messages, collapse = "\n"), "\n")
proceed <- .ask_confirmation(
"Do you want to proceed with the available experiments? (Y/N): ")
if (!proceed) {
validation_results$proceed <- FALSE
return(validation_results)
}
validation_results$messages <- character()  # Clear messages after confirmation
}
# If everything is fine, add success message
if (validation_results$status == "ok") {
validation_results$messages <- c(validation_results$messages,
"✅ All files verified successfully.")
}
return(validation_results)
}
#' @title Extract GTAP Data
#' @description Extracts data from GTAP SL4 and HAR files with simplified filtering options.
#'
#' @param sl4file A data frame containing SL4 mapping information, or FALSE to skip SL4 processing.
#' @param harfile A data frame containing HAR mapping information, or FALSE to skip HAR processing.
#' @param experiment A character vector of experiment names to be processed.
#' @param region_select Optional. A vector specifying regions to filter the data.
#' @param sector_select Optional. A vector specifying sectors to filter the data.
#' @param mapping_info A character string indicating the mapping mode (e.g., "GTAPv7"). Default is "GTAPv7".
#' @param project_dir Optional. Path to the project directory containing the "in" folder.
#' @param input_dir Optional. Directory path for input files; overrides project_dir/in if provided.
#' @param sl4_list_name A character string specifying the global variable name for SL4 plotting data. Default is "sl4.plot.data".
#' @param har_list_name A character string specifying the global variable name for HAR plotting data. Default is "har.plot.data".
#' @param sl4_structure_name A character string specifying the global variable name for SL4 structure. Default is "sl4.structure".
#' @param har_structure_name A character string specifying the global variable name for HAR structure. Default is "har.structure".
#'
#' @return A list containing extracted data with applied filters.
#' @export
#'
#' @examples
#' # Extract specific variables with region filters
#' \dontrun{
#' sl4_selected <- data.frame(
#'   Variable = c("qo", "qgdp", "EV"),
#'   stringsAsFactors = FALSE
#' )
#'
#' result <- plot_gtap_data(
#'   sl4file = sl4_selected,
#'   harfile = FALSE,
#'   experiment = c("baseline", "policy"),
#'   region_select = c("USA", "CHN", "EU"),
#'   input_dir = "D:/GTAP_inputs"
#' )
#' }
#'
plot_gtap_data <- function(sl4file,
harfile,
experiment,
region_select = NULL,
sector_select = NULL,
mapping_info = "GTAPv7",
project_dir = NULL,
input_dir = NULL,
subtotal = FALSE,
sl4_list_name = "sl4.plot.data",
har_list_name = "har.plot.data",
sl4_structure_name = "sl4.structure",
har_structure_name = "har.structure") {
if (is.null(input_dir) && !is.null(project_dir)) {
input_dir <- file.path(project_dir, "in")
}
if (is.null(input_dir)) {
stop("Either input_dir or project_dir must be specified")
}
process_sl4 <- !identical(sl4file, FALSE)
process_har <- !identical(harfile, FALSE)
validation_result <- .validate_extract_files(
sl4map = sl4file,
harmap = harfile,
input.folder = input_dir,
case.name = experiment,
info.mode = mapping_info
)
cat(paste(validation_result$messages, collapse = "\n"), "\n")
if (!validation_result$proceed) {
stop("Process stopped due to validation errors.")
}
files <- list.files(input_dir, full.names = FALSE, ignore.case = TRUE)
sl4_files <- files[grepl("\\.sl4$", files, ignore.case = TRUE)]
har_files <- files[grepl("-wel\\.har$", files, ignore.case = TRUE)]
sl4_bases <- tolower(trimws(sub("\\.sl4$", "", sl4_files, ignore.case = TRUE)))
har_bases <- tolower(trimws(sub("-wel\\.har$", "", har_files, ignore.case = TRUE)))
valid_sl4_cases <- experiment[tolower(experiment) %in% sl4_bases]
valid_har_cases <- experiment[tolower(experiment) %in% har_bases]
# Initialize return objects
result <- list()
sl4_data <- NULL
har_data <- NULL
sl4structure <- NULL
harstructure <- NULL
# Process SL4 files
if (process_sl4 && length(valid_sl4_cases) > 0) {
sl4_variables <- if (is.null(sl4file)) NULL else sl4file$Variable
message("Processing SL4 files...")
# Load SL4 files
sl4_data_raw <- setNames(
lapply(valid_sl4_cases, function(scenario) {
sl4_path <- file.path(input_dir, paste0(scenario, ".sl4"))
if (file.exists(sl4_path)) {
tryCatch({
HARplus::load_sl4x(sl4_path, select_header = sl4_variables)
}, error = function(e) {
message(sprintf("Error processing %s.sl4: %s", scenario, e$message))
return(NULL)
})
} else {
message(sprintf("Skipping %s.sl4 (file not found)", scenario))
return(NULL)
}
}),
valid_sl4_cases
)
sl4_data_raw <- sl4_data_raw[!sapply(sl4_data_raw, is.null)]
if (length(sl4_data_raw) > 0) {
# Generate SL4 variable structure
sl4structure <- do.call(
HARplus::compare_var_structure,
c(list(NULL, keep_unique = TRUE), sl4_data_raw)
)[["match"]]
sl4file_name <- deparse(substitute(sl4file))
sl4structure <- dplyr::left_join(sl4file, sl4structure[c("Variable", "Dimensions")], by = "Variable")
sl4structure <- sl4structure[order(sl4structure$Dimensions), ]
sl4structure$Unit <- NULL
# Assign to global environment if name provided
if (!is.null(sl4_structure_name)) {
assign(sl4file_name, sl4structure, envir = .GlobalEnv)
}
# Use get_data_by_dims with merge=TRUE
sl4_data <- do.call(
HARplus::get_data_by_dims,
c(
list(
patterns = NULL,
experiment_names = names(sl4_data_raw),
merge_data = TRUE,
subtotal_level = subtotal
),
sl4_data_raw
)
)
# Apply mapping info
sl4_data <- add_mapping_info(sl4_data, external_map = sl4file, mapping = mapping_info)
# Apply filters
sl4_data <- .apply_filters(
sl4_data,
region_select = region_select,
experiment_select = experiment,
sector_select = sector_select
)
# Assign to global environment if name provided
if (!is.null(sl4_list_name)) {
assign(sl4_list_name, sl4_data, envir = .GlobalEnv)
}
# Add to result list
result$sl4_data <- sl4_data
}
}
# Process HAR files
if (process_har && length(valid_har_cases) > 0) {
har_variables <- if (is.null(harfile)) NULL else harfile$Variable
message("Processing HAR files...")
# Load HAR files
har_data_raw <- setNames(
lapply(valid_har_cases, function(scenario) {
har_path <- file.path(input_dir, paste0(scenario, "-WEL.har"))
if (file.exists(har_path)) {
tryCatch({
HARplus::load_harx(har_path, select_header = har_variables)
}, error = function(e) {
message(sprintf("Error processing %s-WEL.har: %s", scenario, e$message))
return(NULL)
})
} else {
message(sprintf("Skipping %s-WEL.har (file not found)", scenario))
return(NULL)
}
}),
valid_har_cases
)
har_data_raw <- har_data_raw[!sapply(har_data_raw, is.null)]
if (length(har_data_raw) > 0) {
# Generate HAR variable structure
harstructure <- do.call(
HARplus::compare_var_structure,
c(list(NULL, keep_unique = TRUE), har_data_raw)
)[["match"]]
harfile_name <- deparse(substitute(harfile))
harstructure <- dplyr::left_join(harfile, harstructure[c("Variable", "Dimensions")], by = "Variable")
harstructure <- harstructure[order(harstructure$Dimensions), ]
harstructure$Unit <- NULL
# Assign to global environment if name provided
if (!is.null(har_structure_name)) {
assign(harfile_name, harstructure, envir = .GlobalEnv)
}
# Use get_data_by_dims with merge=TRUE
har_data <- do.call(
HARplus::get_data_by_var,
c(
list(
NULL,
experiment_names = names(har_data_raw),
merge_data = TRUE,
subtotal_level = subtotal
),
har_data_raw
)
)
# Apply mapping info
har_data <- add_mapping_info(har_data, external_map = harfile, mapping = mapping_info)
# Apply filters
har_data <- .apply_filters(
har_data,
region_select = region_select,
experiment_select = experiment,
sector_select = sector_select
)
# Assign to global environment if name provided
if (!is.null(har_list_name)) {
assign(har_list_name, har_data, envir = .GlobalEnv)
}
# Add to result list
result$har_data <- har_data
}
}
message("GTAP plotting data extraction completed!")
return(invisible(NULL))
}
Macros <- do.call(gtap_macros_data, c(as.list(paste0(input.folder, "/", case.name, ".sl4")),
list(experiment_names = case.name)))
# Chunk 1
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
warning = FALSE,
message = FALSE,
eval = requireNamespace("GTAPViz", quietly = TRUE)
)
rm(list=ls())
required_pkgs <- c("tidyverse", "writexl", "dplyr", "devtools",
"openxlsx", "readxl", "knitr", "rmarkdown", "data.table",
"ggplot2", "tcltk", "gridExtra", "haven", "citation", "tinytex", "bookdown", "HARplus")
# Load packages quietly, but only if available
lapply(required_pkgs, function(pkg) {
if (!requireNamespace(pkg, quietly = TRUE)) {
warning(sprintf("Package '%s' is not installed. Please install it before running this vignette.", pkg))
}
})
# Directory
project.folder <- "D:/One Drive/OneDrive - purdue.edu/GTAPViz Data/Plot"
input.folder <- paste0(project.folder, "/in")
output.folder <- paste0(project.folder, "/out")
map.folder <- paste0(project.folder, "/map")
mapping.output <- paste0(map.folder, "/OutputMapping.xlsx")
sl4plot <- readxl::read_xlsx(mapping.output, sheet = "SL4File")
harplot <- readxl::read_xlsx(mapping.output, sheet = "HARFile")
setwd <- "D:/GitHub/GTAPViz/R"
devtools::load_all()
#devtools::install_github("Bodysbobb/GTAPViz")
# Chunk 3: package
library(GTAPViz)
# Chunk 4: Input Setup
# Define experiment name / output name
case.name <- c("US_All", "US_All_RetalTar", "US_All_ReduceTar50", "US_All_RegReduceTar50",
"US_All10", "US_All10_RetalTar", "US_All10_ReduceTar50", "US_All10_RegReduceTar50")
# Adding Description / Unit (Yes/No/GTAPv7/Mix)
info.mode <- "Mix"
# Chunk 5: Preparing Data for Plot
# Region to be plotted
selected_regions <- c("USA", "CHN", "CAN", "ASEAN", "ROW")
# Sector to be plotted (NULL to select all)
selected_sector <- NULL
# Extract data with region and experiment filters
plot.dta <- plot_gtap_data(
sl4file = sl4plot,
harfile = harplot,
experiment  = case.name,
mapping_info = info.mode,
region_select  = selected_regions,
sector_select = selected_sector,
project_dir = project.folder,
subtotal = FALSE
)
# Chunk 7: Optional Convert Unit and Rename Columns
# Convert Value if Needed
sl4.plot.data <- convert_units(
sl4.plot.data,
change_unit_from = c("million USD"),
change_unit_to = c("billion USD"),
adjustment = c("/1000")
)
har.plot.data <- convert_units(
har.plot.data,
change_unit_from = c("million USD"),
change_unit_to = c("billion USD"),
adjustment = c("/1000")
)
# Convert the column name if needed
rename_col <- data.frame(
old = c("REG", "COMM", "ACTS"),
new = c("Region", "Commodity", "Activity")
)
sl4.plot.data <- HARplus::rename_dims(sl4.plot.data, rename_col)
har.plot.data <- HARplus::rename_dims(har.plot.data, rename_col)
# Chunk 9
knitr::include_graphics("https://raw.githubusercontent.com/Bodysbobb/GTAPViz/main/vignettes/images/cpsplot.png")
Macros <- do.call(gtap_macros_data, c(as.list(paste0(input.folder, "/", case.name, ".sl4")),
list(experiment_names = case.name)))
View(Macros)
devtools::check()
devtools::check()
rm(list=ls())
devtools::check()
devtools::check()
devtools::check()
devtools::check()
tools::showNonASCIIfile
tools::showNonASCIIfile("R/GTAPauto.R")
tools::showNonASCIIfile("R/GTAPauto.R")
devtools::check()
devtools::check()
devtools::check()
source("~/.active-rstudio-document", echo=TRUE)
# Chunk 1
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
warning = FALSE,
message = FALSE,
eval = requireNamespace("GTAPViz", quietly = TRUE)
)
rm(list=ls())
required_pkgs <- c("tidyverse", "writexl", "dplyr", "devtools",
"openxlsx", "readxl", "knitr", "rmarkdown", "data.table",
"ggplot2", "tcltk", "gridExtra", "haven", "citation", "tinytex", "bookdown", "HARplus")
# Load packages quietly, but only if available
lapply(required_pkgs, function(pkg) {
if (!requireNamespace(pkg, quietly = TRUE)) {
warning(sprintf("Package '%s' is not installed. Please install it before running this vignette.", pkg))
}
})
# Directory
project.folder <- "D:/One Drive/OneDrive - purdue.edu/GTAPViz Data/Plot"
input.folder <- paste0(project.folder, "/in")
output.folder <- paste0(project.folder, "/out")
map.folder <- paste0(project.folder, "/map")
mapping.output <- paste0(map.folder, "/OutputMapping.xlsx")
sl4plot <- readxl::read_xlsx(mapping.output, sheet = "SL4File")
harplot <- readxl::read_xlsx(mapping.output, sheet = "HARFile")
setwd <- "D:/GitHub/GTAPViz/R"
devtools::load_all()
#devtools::install_github("Bodysbobb/GTAPViz")
# Chunk 3: package
library(GTAPViz)
# Chunk 4: Input Setup
# Define experiment name / output name
case.name <- c("US_All", "US_All_RetalTar", "US_All_ReduceTar50", "US_All_RegReduceTar50",
"US_All10", "US_All10_RetalTar", "US_All10_ReduceTar50", "US_All10_RegReduceTar50")
# Adding Description / Unit (Yes/No/GTAPv7/Mix)
info.mode <- "Mix"
# Chunk 5: Preparing Data for Plot
# Region to be plotted
selected_regions <- c("USA", "CHN", "CAN", "ASEAN", "ROW")
# Sector to be plotted (NULL to select all)
selected_sector <- NULL
# Extract data with region and experiment filters
plot.dta <- plot_gtap_data(
sl4file = sl4plot,
harfile = harplot,
experiment  = case.name,
mapping_info = info.mode,
region_select  = selected_regions,
sector_select = selected_sector,
project_dir = project.folder,
subtotal = FALSE
)
# Chunk 7: Optional Convert Unit and Rename Columns
# Convert Value if Needed
sl4.plot.data <- convert_units(
sl4.plot.data,
change_unit_from = c("million USD"),
change_unit_to = c("billion USD"),
adjustment = c("/1000")
)
har.plot.data <- convert_units(
har.plot.data,
change_unit_from = c("million USD"),
change_unit_to = c("billion USD"),
adjustment = c("/1000")
)
# Convert the column name if needed
rename_col <- data.frame(
old = c("REG", "COMM", "ACTS"),
new = c("Region", "Commodity", "Activity")
)
sl4.plot.data <- HARplus::rename_dims(sl4.plot.data, rename_col)
har.plot.data <- HARplus::rename_dims(har.plot.data, rename_col)
# Chunk 9
knitr::include_graphics("https://raw.githubusercontent.com/Bodysbobb/GTAPViz/main/vignettes/images/cpsplot.png")
View(sl4.plot.data)
rm(list=ls())
devtools::check()
devtools::check()
